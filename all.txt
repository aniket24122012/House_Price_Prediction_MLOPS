# ================= params.yaml =================
model_training:
  random_state: 42
  param_grid:
    n_estimators: [100, 200]
    max_depth: [5, 10]
    min_samples_split: [2, 5]

# ================= dvc.yaml =================
stages:
  data_ingestion:
    cmd: python src/data_ingestion.py
    deps:
      - data/house_data.csv
      - src/data_ingestion.py
    outs:
      - artifacts/processed_data.csv

  preprocessing:
    cmd: python src/preprocessing.py
    deps:
      - artifacts/processed_data.csv
      - src/preprocessing.py
    outs:
      - artifacts/train.csv
      - artifacts/test.csv

  feature_engineering:
    cmd: python src/feature_engineering.py
    deps:
      - artifacts/train.csv
      - artifacts/test.csv
      - src/feature_engineering.py
    outs:
      - artifacts/X_train.csv
      - artifacts/y_train.csv
      - artifacts/X_test.csv
      - artifacts/y_test.csv

  model_training:
    cmd: python src/model_training.py
    deps:
      - artifacts/X_train.csv
      - artifacts/y_train.csv
      - src/model_training.py
      - params.yaml
      - mlflow_tracking/

  model_evaluation:
    cmd: python src/model_evaluation.py
    deps:
      - artifacts/X_test.csv
      - artifacts/y_test.csv
      - src/model_evaluation.py
      - mlflow_tracking/

# ================= src/logger_config.py =================
import logging
import os

def get_logger(name):
    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)
    if not logger.handlers:
        ch = logging.StreamHandler()
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        ch.setFormatter(formatter)
        logger.addHandler(ch)
    return logger

# ================= src/utils.py =================
import os

def ensure_folder(folder_path):
    os.makedirs(folder_path, exist_ok=True)

# ================= src/data_ingestion.py =================
import pandas as pd
from utils import ensure_folder
from logger_config import get_logger

logger = get_logger("data_ingestion")

def main():
    ensure_folder("artifacts")
    df = pd.read_csv("data/house_data.csv")
    df.to_csv("artifacts/processed_data.csv", index=False)
    logger.info("Data ingestion complete.")

if __name__ == "__main__":
    main()

# ================= src/preprocessing.py =================
import pandas as pd
from sklearn.model_selection import train_test_split
from utils import ensure_folder
from logger_config import get_logger

logger = get_logger("preprocessing")

def main():
    ensure_folder("artifacts")
    df = pd.read_csv("artifacts/processed_data.csv")
    train, test = train_test_split(df, test_size=0.2, random_state=42)
    train.to_csv("artifacts/train.csv", index=False)
    test.to_csv("artifacts/test.csv", index=False)
    logger.info("Preprocessing complete.")

if __name__ == "__main__":
    main()

# ================= src/feature_engineering.py =================
import pandas as pd
from utils import ensure_folder
from logger_config import get_logger

logger = get_logger("feature_engineering")

def main():
    ensure_folder("artifacts")
    train = pd.read_csv("artifacts/train.csv")
    test = pd.read_csv("artifacts/test.csv")

    X_train = train.drop(columns=["Price"])
    y_train = train[["Price"]]
    X_test = test.drop(columns=["Price"])
    y_test = test[["Price"]]

    X_train.to_csv("artifacts/X_train.csv", index=False)
    y_train.to_csv("artifacts/y_train.csv", index=False)
    X_test.to_csv("artifacts/X_test.csv", index=False)
    y_test.to_csv("artifacts/y_test.csv", index=False)

    logger.info("Feature engineering complete.")

if __name__ == "__main__":
    main()

# ================= src/model_training.py =================
import os
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import ParameterGrid
from sklearn.metrics import mean_squared_error, r2_score
import mlflow
import mlflow.sklearn
from mlflow.tracking.client import MlflowClient
from mlflow.models.signature import infer_signature
from logger_config import get_logger
from utils import ensure_folder
import yaml

logger = get_logger("model_training")

def load_config():
    with open("params.yaml") as f:
        return yaml.safe_load(f)

def main():
    mlflow_dir = "mlflow_tracking"
    ensure_folder(mlflow_dir)
    mlflow.set_tracking_uri(mlflow_dir)
    mlflow.set_experiment("HousePricePrediction1")

    config = load_config()
    X_train = pd.read_csv("artifacts/X_train.csv")
    y_train = pd.read_csv("artifacts/y_train.csv")

    param_grid = config["model_training"]["param_grid"]
    best_r2 = float("-inf")
    best_model_uri = None
    best_params = None

    for params in ParameterGrid(param_grid):
        with mlflow.start_run():
            logger.info(f"Training with params: {params}")
            
            model = RandomForestRegressor(**params, random_state=config["model_training"]["random_state"])
            model.fit(X_train, y_train.values.ravel())
            
            preds = model.predict(X_train)
            mse = mean_squared_error(y_train, preds)
            r2 = r2_score(y_train, preds)
            
            mlflow.log_params(params)
            mlflow.log_metrics({"train_mse": mse, "train_r2": r2})

            signature = infer_signature(X_train, preds)
            mlflow.sklearn.log_model(
                sk_model=model,
                name="house_price_model",
                signature=signature,
                input_example=X_train.head(3)
            )
            
            logger.info(f"Run finished. MSE: {mse}, R2: {r2}")

            if r2 > best_r2:
                best_r2 = r2
                best_model_uri = f"runs:/{mlflow.active_run().info.run_id}/house_price_model"
                best_params = params

    client = MlflowClient()
    model_details = mlflow.register_model(best_model_uri, "HousePriceModel")
    client.transition_model_version_stage(
        name="HousePriceModel",
        version=model_details.version,
        stage="Production"
    )
    logger.info(f"Best model registered and moved to Production: {best_params}")

if __name__ == "__main__":
    main()

# ================= src/model_evaluation.py =================
import os
import pandas as pd
from sklearn.metrics import mean_squared_error, r2_score
import mlflow
import mlflow.sklearn
from logger_config import get_logger
from utils import ensure_folder

logger = get_logger("model_evaluation")

def main():
    mlflow_dir = "mlflow_tracking"
    ensure_folder(mlflow_dir)
    mlflow.set_tracking_uri(mlflow_dir)
    mlflow.set_experiment("HousePricePrediction1")

    X_test = pd.read_csv("artifacts/X_test.csv")
    y_test = pd.read_csv("artifacts/y_test.csv")

    model = mlflow.sklearn.load_model("models:/HousePriceModel/Production")
    
    preds = model.predict(X_test)
    mse = mean_squared_error(y_test, preds)
    r2 = r2_score(y_test, preds)

    with mlflow.start_run():
        mlflow.log_metrics({"test_mse": mse, "test_r2": r2})

    logger.info(f"Test MSE: {mse}, R2: {r2}")
    logger.info("Evaluation complete and metrics logged in MLflow.")
